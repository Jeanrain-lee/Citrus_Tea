{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_keras_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-vGg6I7CRGA",
        "colab_type": "text"
      },
      "source": [
        "https://www.tensorflow.org/api_docs/python/tf/keras/Model 참조로 cnn 구현해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zpzH7H1936I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpz7_b1a6yj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. 모듈 import\n",
        "import tensorflow as tf\n",
        "import os, numpy as np\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trJWB94T9zNL",
        "colab_type": "code",
        "outputId": "1989f482-0e93-4670-d5b3-3cd613e31e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 2. npy 데이터를 불러와서 모델 학습(64 x 64 사이즈의 이미지 약 25000개)\n",
        "X_train, X_test, y_train, y_test = np.load(\"/content/drive/My Drive/last.npy\", allow_pickle=True)\n",
        "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')  \n",
        "print(f'X_test: {X_test.shape}, y_test: {y_test.shape}') \n",
        "\n",
        "# uint8 -> float32 타입 변환\n",
        "X_train = tf.cast(X_train, tf.float32)\n",
        "X_test = tf.cast(X_test, tf.float32)\n",
        "y_train = tf.cast(y_train, tf.float32)\n",
        "y_test = tf.cast(y_test, tf.float32)\n",
        "X_train.dtype\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (20802, 64, 64, 3), y_train: (20802, 5)\n",
            "X_test: (5201, 64, 64, 3), y_test: (5201, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxuooCn1jAu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. CNN 모델 구성\n",
        "inputs = tf.keras.Input(shape=(64, 64, 3))\n",
        "class firstcnn(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(firstcnn, self).__init__()\n",
        "    \n",
        "    self.conv1 = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu)\n",
        "    self.pool1 = MaxPooling2D(pool_size=(2, 2))\n",
        "    \n",
        "    self.conv2 = Conv2D(32, kernel_size=(3, 3), padding='same', activation=tf.nn.relu)\n",
        "    self.pool2 = MaxPooling2D(pool_size=(2, 2))\n",
        "\n",
        "    self.conv3 = Conv2D(32, kernel_size=(3, 3), padding='same', activation=tf.nn.relu)\n",
        "    self.pool3 = MaxPooling2D(pool_size=(2, 2))\n",
        "    self.dropout1 = Dropout(0.25)\n",
        "\n",
        "    self.conv4 = Conv2D(64, kernel_size=(3, 3), padding='same', activation=tf.nn.relu)\n",
        "    self.pool4 = MaxPooling2D(pool_size=(2, 2))\n",
        "    self.dropout2 = Dropout(0.25)\n",
        "    self.flat = Flatten()\n",
        "    \n",
        "    self.d1 = Dense(256, activation=tf.nn.relu)\n",
        "    self.dropout3 = Dropout(0.5)\n",
        "    self.d2 = Dense(5, activation=tf.nn.softmax)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.pool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.pool2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.pool3(x)\n",
        "    x = self.dropout1(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.pool4(x)\n",
        "    x = self.dropout2(x)\n",
        "    x = self.flat(x)\n",
        "    x = self.d1(x)\n",
        "    x = self.dropout3(x)\n",
        "    return self.d2(x)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFNYnL4ZYDJR",
        "colab_type": "code",
        "outputId": "6d30ebe0-7d7c-4ab6-d84b-caf068d57beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnj_xm5nCCzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = firstcnn()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XZtqI4OjDst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8WgJgNTjGNq",
        "colab_type": "code",
        "outputId": "e1ff72ae-c810-48c8-adda-3fe90ddc0ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 5. 모델 학습\n",
        "model_dir = \"./model\"\n",
        "if not os.path.exists(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "model_path = model_dir + '/test.model'\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "hist = model.fit(X_train, y_train, epochs=200, batch_size=200, validation_split=0.2, callbacks=[checkpoint, early_stopping])\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 16641 samples, validate on 4161 samples\n",
            "Epoch 1/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 3.6400 - accuracy: 0.3188\n",
            "Epoch 00001: val_loss improved from inf to 1.17715, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 146us/sample - loss: 3.5760 - accuracy: 0.3223 - val_loss: 1.1772 - val_accuracy: 0.5124\n",
            "Epoch 2/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 1.1568 - accuracy: 0.5041\n",
            "Epoch 00002: val_loss improved from 1.17715 to 0.90663, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 98us/sample - loss: 1.1543 - accuracy: 0.5059 - val_loss: 0.9066 - val_accuracy: 0.6626\n",
            "Epoch 3/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.9147 - accuracy: 0.6406\n",
            "Epoch 00003: val_loss improved from 0.90663 to 0.69031, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 97us/sample - loss: 0.9161 - accuracy: 0.6402 - val_loss: 0.6903 - val_accuracy: 0.7414\n",
            "Epoch 4/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.7882 - accuracy: 0.6912\n",
            "Epoch 00004: val_loss did not improve from 0.69031\n",
            "16641/16641 [==============================] - 2s 93us/sample - loss: 0.7877 - accuracy: 0.6918 - val_loss: 0.6950 - val_accuracy: 0.7284\n",
            "Epoch 5/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.7255 - accuracy: 0.7202\n",
            "Epoch 00005: val_loss improved from 0.69031 to 0.60651, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.7244 - accuracy: 0.7206 - val_loss: 0.6065 - val_accuracy: 0.7705\n",
            "Epoch 6/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.6912 - accuracy: 0.7268\n",
            "Epoch 00006: val_loss did not improve from 0.60651\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.6916 - accuracy: 0.7272 - val_loss: 0.6176 - val_accuracy: 0.7553\n",
            "Epoch 7/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.6872 - accuracy: 0.7346\n",
            "Epoch 00007: val_loss improved from 0.60651 to 0.58665, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.6892 - accuracy: 0.7333 - val_loss: 0.5866 - val_accuracy: 0.7835\n",
            "Epoch 8/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.6498 - accuracy: 0.7446\n",
            "Epoch 00008: val_loss improved from 0.58665 to 0.55499, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 98us/sample - loss: 0.6498 - accuracy: 0.7436 - val_loss: 0.5550 - val_accuracy: 0.7782\n",
            "Epoch 9/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.6199 - accuracy: 0.7537\n",
            "Epoch 00009: val_loss did not improve from 0.55499\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.6188 - accuracy: 0.7539 - val_loss: 0.5635 - val_accuracy: 0.7830\n",
            "Epoch 10/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.5978 - accuracy: 0.7630\n",
            "Epoch 00010: val_loss improved from 0.55499 to 0.53830, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.5974 - accuracy: 0.7634 - val_loss: 0.5383 - val_accuracy: 0.7883\n",
            "Epoch 11/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.6234 - accuracy: 0.7566\n",
            "Epoch 00011: val_loss improved from 0.53830 to 0.52529, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.6234 - accuracy: 0.7566 - val_loss: 0.5253 - val_accuracy: 0.7974\n",
            "Epoch 12/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.5544 - accuracy: 0.7856\n",
            "Epoch 00012: val_loss improved from 0.52529 to 0.51017, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.5537 - accuracy: 0.7858 - val_loss: 0.5102 - val_accuracy: 0.8008\n",
            "Epoch 13/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.5411 - accuracy: 0.7873\n",
            "Epoch 00013: val_loss improved from 0.51017 to 0.49738, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 95us/sample - loss: 0.5404 - accuracy: 0.7871 - val_loss: 0.4974 - val_accuracy: 0.8053\n",
            "Epoch 14/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.5296 - accuracy: 0.7898\n",
            "Epoch 00014: val_loss improved from 0.49738 to 0.48449, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 95us/sample - loss: 0.5304 - accuracy: 0.7891 - val_loss: 0.4845 - val_accuracy: 0.8027\n",
            "Epoch 15/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.5249 - accuracy: 0.7913\n",
            "Epoch 00015: val_loss improved from 0.48449 to 0.46111, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.5247 - accuracy: 0.7915 - val_loss: 0.4611 - val_accuracy: 0.8195\n",
            "Epoch 16/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 0.5200 - accuracy: 0.7959\n",
            "Epoch 00016: val_loss improved from 0.46111 to 0.44477, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.5190 - accuracy: 0.7964 - val_loss: 0.4448 - val_accuracy: 0.8231\n",
            "Epoch 17/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.4926 - accuracy: 0.8028\n",
            "Epoch 00017: val_loss improved from 0.44477 to 0.42539, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.4929 - accuracy: 0.8027 - val_loss: 0.4254 - val_accuracy: 0.8311\n",
            "Epoch 18/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.4829 - accuracy: 0.8107\n",
            "Epoch 00018: val_loss did not improve from 0.42539\n",
            "16641/16641 [==============================] - 2s 92us/sample - loss: 0.4843 - accuracy: 0.8109 - val_loss: 0.4517 - val_accuracy: 0.8248\n",
            "Epoch 19/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.4863 - accuracy: 0.8063\n",
            "Epoch 00019: val_loss did not improve from 0.42539\n",
            "16641/16641 [==============================] - 2s 91us/sample - loss: 0.4882 - accuracy: 0.8056 - val_loss: 0.4781 - val_accuracy: 0.8075\n",
            "Epoch 20/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.4619 - accuracy: 0.8165\n",
            "Epoch 00020: val_loss did not improve from 0.42539\n",
            "16641/16641 [==============================] - 2s 92us/sample - loss: 0.4633 - accuracy: 0.8154 - val_loss: 0.4524 - val_accuracy: 0.8267\n",
            "Epoch 21/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.4518 - accuracy: 0.8199\n",
            "Epoch 00021: val_loss did not improve from 0.42539\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.4512 - accuracy: 0.8200 - val_loss: 0.4281 - val_accuracy: 0.8279\n",
            "Epoch 22/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 0.4491 - accuracy: 0.8207\n",
            "Epoch 00022: val_loss improved from 0.42539 to 0.40579, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.4506 - accuracy: 0.8202 - val_loss: 0.4058 - val_accuracy: 0.8419\n",
            "Epoch 23/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.4231 - accuracy: 0.8320\n",
            "Epoch 00023: val_loss did not improve from 0.40579\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.4230 - accuracy: 0.8322 - val_loss: 0.4114 - val_accuracy: 0.8474\n",
            "Epoch 24/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.4190 - accuracy: 0.8310\n",
            "Epoch 00024: val_loss did not improve from 0.40579\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.4214 - accuracy: 0.8304 - val_loss: 0.4663 - val_accuracy: 0.8125\n",
            "Epoch 25/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.4203 - accuracy: 0.8338\n",
            "Epoch 00025: val_loss improved from 0.40579 to 0.40300, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 95us/sample - loss: 0.4202 - accuracy: 0.8337 - val_loss: 0.4030 - val_accuracy: 0.8493\n",
            "Epoch 26/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 0.4035 - accuracy: 0.8410\n",
            "Epoch 00026: val_loss improved from 0.40300 to 0.37961, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.4041 - accuracy: 0.8408 - val_loss: 0.3796 - val_accuracy: 0.8469\n",
            "Epoch 27/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 0.4187 - accuracy: 0.8349\n",
            "Epoch 00027: val_loss did not improve from 0.37961\n",
            "16641/16641 [==============================] - 2s 95us/sample - loss: 0.4201 - accuracy: 0.8344 - val_loss: 0.3845 - val_accuracy: 0.8512\n",
            "Epoch 28/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8456\n",
            "Epoch 00028: val_loss improved from 0.37961 to 0.35103, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.3904 - accuracy: 0.8457 - val_loss: 0.3510 - val_accuracy: 0.8560\n",
            "Epoch 29/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.3763 - accuracy: 0.8519\n",
            "Epoch 00029: val_loss did not improve from 0.35103\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.3765 - accuracy: 0.8521 - val_loss: 0.4108 - val_accuracy: 0.8349\n",
            "Epoch 30/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.3696 - accuracy: 0.8532\n",
            "Epoch 00030: val_loss did not improve from 0.35103\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.3694 - accuracy: 0.8533 - val_loss: 0.3961 - val_accuracy: 0.8472\n",
            "Epoch 31/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8493\n",
            "Epoch 00031: val_loss improved from 0.35103 to 0.33947, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.3867 - accuracy: 0.8491 - val_loss: 0.3395 - val_accuracy: 0.8654\n",
            "Epoch 32/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.3600 - accuracy: 0.8588\n",
            "Epoch 00032: val_loss improved from 0.33947 to 0.32727, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 95us/sample - loss: 0.3597 - accuracy: 0.8590 - val_loss: 0.3273 - val_accuracy: 0.8664\n",
            "Epoch 33/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.3622 - accuracy: 0.8555\n",
            "Epoch 00033: val_loss did not improve from 0.32727\n",
            "16641/16641 [==============================] - 2s 92us/sample - loss: 0.3626 - accuracy: 0.8554 - val_loss: 0.3609 - val_accuracy: 0.8568\n",
            "Epoch 34/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.3529 - accuracy: 0.8596\n",
            "Epoch 00034: val_loss did not improve from 0.32727\n",
            "16641/16641 [==============================] - 2s 95us/sample - loss: 0.3535 - accuracy: 0.8591 - val_loss: 0.3683 - val_accuracy: 0.8503\n",
            "Epoch 35/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.3572 - accuracy: 0.8563\n",
            "Epoch 00035: val_loss improved from 0.32727 to 0.32629, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 98us/sample - loss: 0.3567 - accuracy: 0.8567 - val_loss: 0.3263 - val_accuracy: 0.8743\n",
            "Epoch 36/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.3479 - accuracy: 0.8619\n",
            "Epoch 00036: val_loss did not improve from 0.32629\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.3486 - accuracy: 0.8619 - val_loss: 0.3881 - val_accuracy: 0.8534\n",
            "Epoch 37/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.3507 - accuracy: 0.8657\n",
            "Epoch 00037: val_loss did not improve from 0.32629\n",
            "16641/16641 [==============================] - 2s 93us/sample - loss: 0.3514 - accuracy: 0.8649 - val_loss: 0.3687 - val_accuracy: 0.8534\n",
            "Epoch 38/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.3489 - accuracy: 0.8619\n",
            "Epoch 00038: val_loss improved from 0.32629 to 0.31541, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 95us/sample - loss: 0.3468 - accuracy: 0.8628 - val_loss: 0.3154 - val_accuracy: 0.8731\n",
            "Epoch 39/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 0.3114 - accuracy: 0.8763\n",
            "Epoch 00039: val_loss did not improve from 0.31541\n",
            "16641/16641 [==============================] - 2s 97us/sample - loss: 0.3127 - accuracy: 0.8762 - val_loss: 0.3306 - val_accuracy: 0.8736\n",
            "Epoch 40/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.3208 - accuracy: 0.8743\n",
            "Epoch 00040: val_loss did not improve from 0.31541\n",
            "16641/16641 [==============================] - 2s 95us/sample - loss: 0.3194 - accuracy: 0.8746 - val_loss: 0.3168 - val_accuracy: 0.8784\n",
            "Epoch 41/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.3205 - accuracy: 0.8701\n",
            "Epoch 00041: val_loss did not improve from 0.31541\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.3196 - accuracy: 0.8705 - val_loss: 0.3235 - val_accuracy: 0.8758\n",
            "Epoch 42/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.3012 - accuracy: 0.8804\n",
            "Epoch 00042: val_loss did not improve from 0.31541\n",
            "16641/16641 [==============================] - 2s 100us/sample - loss: 0.3012 - accuracy: 0.8804 - val_loss: 0.3531 - val_accuracy: 0.8613\n",
            "Epoch 43/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.3152 - accuracy: 0.8750\n",
            "Epoch 00043: val_loss improved from 0.31541 to 0.29076, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 99us/sample - loss: 0.3145 - accuracy: 0.8756 - val_loss: 0.2908 - val_accuracy: 0.8854\n",
            "Epoch 44/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.8807\n",
            "Epoch 00044: val_loss did not improve from 0.29076\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.3049 - accuracy: 0.8813 - val_loss: 0.3106 - val_accuracy: 0.8772\n",
            "Epoch 45/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 0.2996 - accuracy: 0.8795\n",
            "Epoch 00045: val_loss improved from 0.29076 to 0.28901, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 95us/sample - loss: 0.3000 - accuracy: 0.8790 - val_loss: 0.2890 - val_accuracy: 0.8858\n",
            "Epoch 46/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 0.2847 - accuracy: 0.8857\n",
            "Epoch 00046: val_loss did not improve from 0.28901\n",
            "16641/16641 [==============================] - 2s 92us/sample - loss: 0.2844 - accuracy: 0.8857 - val_loss: 0.3200 - val_accuracy: 0.8755\n",
            "Epoch 47/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.2848 - accuracy: 0.8882\n",
            "Epoch 00047: val_loss did not improve from 0.28901\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.2852 - accuracy: 0.8880 - val_loss: 0.2975 - val_accuracy: 0.8837\n",
            "Epoch 48/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.2818 - accuracy: 0.8864\n",
            "Epoch 00048: val_loss did not improve from 0.28901\n",
            "16641/16641 [==============================] - 2s 93us/sample - loss: 0.2827 - accuracy: 0.8860 - val_loss: 0.3320 - val_accuracy: 0.8719\n",
            "Epoch 49/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.2961 - accuracy: 0.8845\n",
            "Epoch 00049: val_loss improved from 0.28901 to 0.28622, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.2963 - accuracy: 0.8844 - val_loss: 0.2862 - val_accuracy: 0.8873\n",
            "Epoch 50/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.2811 - accuracy: 0.8877\n",
            "Epoch 00050: val_loss improved from 0.28622 to 0.26963, saving model to ./model/test.model\n",
            "16641/16641 [==============================] - 2s 96us/sample - loss: 0.2796 - accuracy: 0.8883 - val_loss: 0.2696 - val_accuracy: 0.8916\n",
            "Epoch 51/200\n",
            "16600/16641 [============================>.] - ETA: 0s - loss: 0.2807 - accuracy: 0.8901\n",
            "Epoch 00051: val_loss did not improve from 0.26963\n",
            "16641/16641 [==============================] - 2s 93us/sample - loss: 0.2803 - accuracy: 0.8902 - val_loss: 0.3067 - val_accuracy: 0.8798\n",
            "Epoch 52/200\n",
            "16200/16641 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.8925\n",
            "Epoch 00052: val_loss did not improve from 0.26963\n",
            "16641/16641 [==============================] - 2s 92us/sample - loss: 0.2685 - accuracy: 0.8927 - val_loss: 0.3221 - val_accuracy: 0.8707\n",
            "Epoch 53/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.8913\n",
            "Epoch 00053: val_loss did not improve from 0.26963\n",
            "16641/16641 [==============================] - 2s 94us/sample - loss: 0.2690 - accuracy: 0.8913 - val_loss: 0.2718 - val_accuracy: 0.8916\n",
            "Epoch 54/200\n",
            "16400/16641 [============================>.] - ETA: 0s - loss: 0.2690 - accuracy: 0.8952\n",
            "Epoch 00054: val_loss did not improve from 0.26963\n",
            "16641/16641 [==============================] - 2s 92us/sample - loss: 0.2697 - accuracy: 0.8952 - val_loss: 0.3143 - val_accuracy: 0.8726\n",
            "Epoch 55/200\n",
            "16000/16641 [===========================>..] - ETA: 0s - loss: 0.2667 - accuracy: 0.8929\n",
            "Epoch 00055: val_loss did not improve from 0.26963\n",
            "16641/16641 [==============================] - 2s 93us/sample - loss: 0.2688 - accuracy: 0.8918 - val_loss: 0.2706 - val_accuracy: 0.8909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGhmlkIkPS1P",
        "colab_type": "code",
        "outputId": "cfe5e6ad-fcec-4a69-8ad3-59f3d73e0531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# loss 그래프\n",
        "train_loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "x = range(len(train_loss))\n",
        "plt.plot(x, train_loss, marker='.', color='red', label='Train loss')\n",
        "plt.plot(x, val_loss, marker='.', color='blue', label='Val loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss during epochs')\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCTmFAQiIjGnIBARiTkFgYhIzP0/zmVCqVhJnUkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD84vg0tjxKM",
        "colab_type": "code",
        "outputId": "d497d203-4863-4cb4-d607-255ff3c8a409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# acc 그래프\n",
        "train_acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "\n",
        "plt.plot(x, train_acc, marker='.', c='red', label='Train Acc.')\n",
        "plt.plot(x, val_acc, marker='.', c='blue', label='Val Acc.')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy during epochs')\n",
        "plt.show()\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTIKzQGCMMQnOAoExxiS4/we4HCyZzhr97wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1hd9oH26vcZ",
        "colab_type": "code",
        "outputId": "78c80150-febb-4430-8425-76b265ec9b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Test set으로 모델 평가\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Training loss:', score[0])\n",
        "print('Training accuracy: ', score[1])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.2784612458202844\n",
            "Training accuracy:  0.8940588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsCClGK_RytO",
        "colab_type": "code",
        "outputId": "eb0ea9a7-43d5-4825-9d33-205e4b6f268c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "test_true = np.argmax(y_test, axis=1)\n",
        "test_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "cm = confusion_matrix(test_true, test_pred)\n",
        "print(cm)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 955   23   19    7    4]\n",
            " [  39  851  149   14    2]\n",
            " [  76  153  798    6    1]\n",
            " [   8   21    2 1107   13]\n",
            " [   3    0    0   11  939]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kz2HMf01WvM",
        "colab_type": "code",
        "outputId": "22720c56-05a0-4092-e510-ab58cf19895d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(test_true, test_pred, target_names=os.listdir('/content/drive/My Drive/data_label'))\n",
        "print(report)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       nevus       0.88      0.95      0.91      1008\n",
            "          df       0.81      0.81      0.81      1055\n",
            "      eschar       0.82      0.77      0.80      1034\n",
            "          vl       0.97      0.96      0.96      1151\n",
            "         mel       0.98      0.99      0.98       953\n",
            "\n",
            "    accuracy                           0.89      5201\n",
            "   macro avg       0.89      0.89      0.89      5201\n",
            "weighted avg       0.89      0.89      0.89      5201\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiBk_5TRwsFE",
        "colab_type": "text"
      },
      "source": [
        "˙ 정확도 약 89% </br>\n",
        "˙ 쯔쯔가무시 병변 레이블인 eschar의 정확도를 높이는데 1차 목표 </br>\n",
        "˙ \n",
        "˙ 모양새가 서로 비슷해 진단이 어렵다는 vl과 mel의 정확도 주의"
      ]
    }
  ]
}
