{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_resnet50_keras_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-qGaCs1Hih1G16wfIWHyRzr3nrfLWh8T",
      "authorship_tag": "ABX9TyOC0corwBiIneWV+gVlCayM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAzhqHm9q0Q8",
        "colab_type": "text"
      },
      "source": [
        "# ResNet50\n",
        ":: 층을 깊게 하는 것이 성능 향상에는 중요, 하지만 너무 깊어도 성능이 떨어지기도 함 </br>\n",
        "=> 이 문제 해결 위해 스킵 연결(skip connection) 도입 </br>\n",
        "입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조 </br>\n",
        "Keras의 ResNet + 내가 만든 레이어 붙여서 학습 </br>\n",
        "참조 :: https://rarena.tistory.com/entry/keras-%ED%8A%B9%EC%A0%95-%EB%AA%A8%EB%8D%B8%EB%A1%9C%EB%93%9C%ED%95%98%EC%97%AC-%EB%82%B4-%EB%A0%88%EC%9D%B4%EC%96%B4 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0olyxxwBtn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j2eVDLv80q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. 필요 모듈 import\n",
        "import tensorflow as tf\n",
        "import os, numpy as np\n",
        "import tensorflow.keras.applications.resnet50 as m\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import BatchNormalization, Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers import LeakyReLU\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ3dGrZZ8-LR",
        "colab_type": "code",
        "outputId": "949cb585-c7bb-45e6-d478-c42668a891cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 2. npy 데이터를 불러와서 모델 학습\n",
        "X_train, X_test, y_train, y_test = np.load(\"/content/drive/My Drive/last.npy\", allow_pickle=True)\n",
        "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')  \n",
        "print(f'X_test: {X_test.shape}, y_test: {y_test.shape}') \n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (20802, 64, 64, 3), y_train: (20802, 5)\n",
            "X_test: (5201, 64, 64, 3), y_test: (5201, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni67QdFiqQR2",
        "colab_type": "code",
        "outputId": "c2aa988d-b6a5-426c-f2d1-d4503503a012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 3. model 생성\n",
        "model = m.ResNet50(input_shape=(64, 64, 3), include_top=False, weights='imagenet', pooling='max')\n",
        "x = model.output\n",
        "x = Dense(1024, kernel_initializer='TruncatedNormal')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(512, kernel_initializer='TruncatedNormal')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, kernel_initializer='RandomUniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(5, activation=tf.nn.softmax)(x)\n",
        "model = tf.keras.Model(model.input, x)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 32, 32, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 16, 16, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 16, 16, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 16, 16, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 16, 16, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 16, 16, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 16, 16, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 16, 16, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 16, 16, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 16, 16, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 16, 16, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 16, 16, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 16, 16, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 16, 16, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 8, 8, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 8, 8, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 8, 8, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 8, 8, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 8, 8, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 8, 8, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 8, 8, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 8, 8, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 8, 8, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 8, 8, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 8, 8, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 8, 8, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 8, 8, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 4, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 4, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 4, 4, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 4, 4, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 4, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 4, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 4, 4, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 4, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 4, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 4, 4, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 4, 4, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 4, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 4, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 4, 4, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 4, 4, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 4, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 4, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 4, 4, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 4, 4, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 4, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 4, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 4, 4, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 4, 4, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 2, 2, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 2, 2, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 2, 2, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 2, 2, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pool (GlobalMaxPooling2D)   (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 1024)         2098176     max_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 1024)         4096        dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 1024)         0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 1024)         0           activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 512)          524800      dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 512)          2048        dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 512)          0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 512)          0           activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 256)          131328      dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 256)          1024        dense_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 5)            1285        batch_normalization_35[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 26,350,469\n",
            "Trainable params: 26,293,765\n",
            "Non-trainable params: 56,704\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CT9pJ378RsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.07, clipvalue=0.6), metrics=['accuracy'])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4ETMJ4-FIju",
        "colab_type": "code",
        "outputId": "6282d964-171e-4e42-c0cd-060c12ffd7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        }
      },
      "source": [
        "# 5. 모델 학습\n",
        "model_dir = \"./model\"\n",
        "if not os.path.exists(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "model_path = model_dir + '/test.model'\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "hist = model.fit(X_train, y_train, epochs=50, batch_size=200, callbacks=[checkpoint, early_stopping], validation_split=0.2)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.9780 - accuracy: 0.6120\n",
            "Epoch 00001: val_loss improved from inf to 2.62243, saving model to ./model/test.model\n",
            "INFO:tensorflow:Assets written to: ./model/test.model/assets\n",
            "84/84 [==============================] - 44s 523ms/step - loss: 0.9780 - accuracy: 0.6120 - val_loss: 2.6224 - val_accuracy: 0.3778\n",
            "Epoch 2/50\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.8365\n",
            "Epoch 00002: val_loss improved from 2.62243 to 0.70080, saving model to ./model/test.model\n",
            "INFO:tensorflow:Assets written to: ./model/test.model/assets\n",
            "84/84 [==============================] - 42s 505ms/step - loss: 0.4229 - accuracy: 0.8365 - val_loss: 0.7008 - val_accuracy: 0.7501\n",
            "Epoch 3/50\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.8926\n",
            "Epoch 00003: val_loss improved from 0.70080 to 0.41665, saving model to ./model/test.model\n",
            "INFO:tensorflow:Assets written to: ./model/test.model/assets\n",
            "84/84 [==============================] - 43s 508ms/step - loss: 0.2819 - accuracy: 0.8926 - val_loss: 0.4166 - val_accuracy: 0.8395\n",
            "Epoch 4/50\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9219\n",
            "Epoch 00004: val_loss improved from 0.41665 to 0.31034, saving model to ./model/test.model\n",
            "INFO:tensorflow:Assets written to: ./model/test.model/assets\n",
            "84/84 [==============================] - 43s 508ms/step - loss: 0.2066 - accuracy: 0.9219 - val_loss: 0.3103 - val_accuracy: 0.8695\n",
            "Epoch 5/50\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.9462\n",
            "Epoch 00005: val_loss improved from 0.31034 to 0.25524, saving model to ./model/test.model\n",
            "INFO:tensorflow:Assets written to: ./model/test.model/assets\n",
            "84/84 [==============================] - 42s 504ms/step - loss: 0.1508 - accuracy: 0.9462 - val_loss: 0.2552 - val_accuracy: 0.9015\n",
            "Epoch 6/50\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9623\n",
            "Epoch 00006: val_loss did not improve from 0.25524\n",
            "84/84 [==============================] - 18s 211ms/step - loss: 0.1098 - accuracy: 0.9623 - val_loss: 0.3218 - val_accuracy: 0.8870\n",
            "Epoch 7/50\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9735\n",
            "Epoch 00007: val_loss did not improve from 0.25524\n",
            "84/84 [==============================] - 18s 213ms/step - loss: 0.0773 - accuracy: 0.9735 - val_loss: 0.2820 - val_accuracy: 0.8993\n",
            "Epoch 8/50\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9837\n",
            "Epoch 00008: val_loss did not improve from 0.25524\n",
            "84/84 [==============================] - 18s 212ms/step - loss: 0.0549 - accuracy: 0.9837 - val_loss: 0.3141 - val_accuracy: 0.8861\n",
            "Epoch 9/50\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9891\n",
            "Epoch 00009: val_loss did not improve from 0.25524\n",
            "84/84 [==============================] - 17s 208ms/step - loss: 0.0417 - accuracy: 0.9891 - val_loss: 0.2668 - val_accuracy: 0.9159\n",
            "Epoch 10/50\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9915\n",
            "Epoch 00010: val_loss did not improve from 0.25524\n",
            "84/84 [==============================] - 17s 208ms/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.2773 - val_accuracy: 0.9118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHVmnbDmFtvM",
        "colab_type": "code",
        "outputId": "b75b398a-a4c2-47dd-9d8f-c4698dd61ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# loss 그래프\n",
        "train_loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "x = range(len(train_loss))\n",
        "plt.plot(x, train_loss, marker='.', color='red', label='Train loss')\n",
        "plt.plot(x, val_loss, marker='.', color='blue', label='Val loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss during epochs')\n",
        "plt.show()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBEpcAoCEZECpyAQESlw/x9eGYCPpAWRJwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4hQf9bpHe6-",
        "colab_type": "code",
        "outputId": "4b37484c-6427-4937-acfe-da9a8b1f43a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# acc 그래프\n",
        "train_acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "\n",
        "plt.plot(x, train_acc, marker='.', c='red', label='Train Acc.')\n",
        "plt.plot(x, val_acc, marker='.', c='blue', label='Val Acc.')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy during epochs')\n",
        "plt.show()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgCrHSZ-Hi3y",
        "colab_type": "code",
        "outputId": "af060a33-20dc-4173-c58f-12d3e046177c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Test set으로 모델 평가\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Training loss:', score[0])\n",
        "print('Training accuracy: ', score[1])"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.2778761684894562\n",
            "Training accuracy:  0.9069409966468811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfJvq42PMwAx",
        "colab_type": "code",
        "outputId": "ac84d041-08c7-41c4-c7c8-1ded6d1757e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "test_true = np.argmax(y_test, axis=1)\n",
        "print(test_true)\n",
        "test_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "print(test_pred)\n",
        "\n",
        "cm = confusion_matrix(test_true, test_pred)\n",
        "print(cm)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 3 3 ... 1 2 3]\n",
            "[0 3 3 ... 1 2 3]\n",
            "[[ 931   23   48    1    5]\n",
            " [   9  845  199    1    1]\n",
            " [  20  106  904    1    3]\n",
            " [   8   21   18 1098    6]\n",
            " [   5    0    4    5  939]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-DN8n3TM1ZJ",
        "colab_type": "code",
        "outputId": "6d16fefd-b71f-4a12-a5ee-02d64193c8df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(test_true, test_pred, target_names=os.listdir('/content/drive/My Drive/data_label'))\n",
        "print(report)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       nevus       0.96      0.92      0.94      1008\n",
            "          df       0.85      0.80      0.82      1055\n",
            "      eschar       0.77      0.87      0.82      1034\n",
            "          vl       0.99      0.95      0.97      1151\n",
            "         mel       0.98      0.99      0.98       953\n",
            "\n",
            "    accuracy                           0.91      5201\n",
            "   macro avg       0.91      0.91      0.91      5201\n",
            "weighted avg       0.91      0.91      0.91      5201\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfxECVQawmPY",
        "colab_type": "text"
      },
      "source": [
        "˙ 프로젝트 진행 기간에 구현했던 것과 비교해 한 epoch 당 학습 시간 약 8초 감소 </br>\n",
        "˙ 오버피팅 눈에 띄게 감소, 안정된 그래프 </br>\n",
        "˙ 정확도 4% 개선, 구버전과 비교시 vl과 mel의 구별 성능이 매우 향상 </br>\n",
        "˙ eschar 부분에서도 전반적으로 성능 향상을 보였으나 정밀도에서 다소 성능이 떨어지는 모습을 보임, 개선 필요\n",
        "\n"
      ]
    }
  ]
}